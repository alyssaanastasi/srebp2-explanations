{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Experiments\n",
    "\n",
    "This jupyter notebook file consists of more advanced and computationally expensive experiments in order to truly examine the results of using the different explanation methods. \n",
    "\n",
    "- Measure fidelity when edge mask is set to None to assess the importance of node features alone\n",
    "    - Plot fidelity curves for various values of k (10, 20, 40, 80)\n",
    "- Plot fidelity curves for subgraphs with various values of k (10, 20, 40, 80)\n",
    "- Revised stability calculations\n",
    "    - Can we do 5  runs for each of 10  instances?\n",
    "    - Calculate average Jaccard similarity for each instance\n",
    "    - Make a box plot or something similar to show distribution of similarity measures across instances\n",
    "    - Per Yuriy’s suggestion, we could also calculate Ruzicka similarity (https://en.wikipedia.org/wiki/Jaccard_index) on soft masks\n",
    "- Additional explainer methods\n",
    "    - DummyExplainer (random baseline)\n",
    "    - CaptumExplainer Saliency (not essential, but would be nice to include)\n",
    "- Conduct evaluation on another GNN\n",
    "    - EPGAT maybe?  (https://pubmed.ncbi.nlm.nih.gov/33497339/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "# install necessary packages\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.explain import GNNExplainer,Explainer,GraphMaskExplainer,PGExplainer, DummyExplainer\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv\n",
    "from torch.nn import Linear,Softmax\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import pickle\n",
    "from torch_geometric.explain.metric import fidelity, characterization_score\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGAT_1(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A graph attention network with 4 graph layers and 2 linear layers.\n",
    "    Uses v2 of graph attention that provides dynamic instead of static attention.\n",
    "    The graph layer dimension and number of attention heads can be specified.\n",
    "    \"\"\"\n",
    "    #torch.device('mps')\n",
    "    def __init__(self, dataset, dim=8, num_heads=4):\n",
    "        super(SimpleGAT_1, self).__init__()\n",
    "        torch.manual_seed(seed=123)\n",
    "        self.conv1 = GATv2Conv(in_channels=dataset.num_features, out_channels=dim, heads=num_heads,edge_dim=dataset.edge_attr.shape[1])\n",
    "        self.conv2 = GATv2Conv(in_channels=dim * num_heads, out_channels=dim, heads=num_heads,edge_dim=dataset.edge_attr.shape[1])\n",
    "        self.lin1 = Linear(dim * num_heads,dim)\n",
    "        self.lin2 = Linear(dim,1)\n",
    "\n",
    "    def forward(self, x, edge_index,edge_attr):\n",
    "        h = self.conv1(x, edge_index,edge_attr).relu()\n",
    "        h = self.conv2(h, edge_index,edge_attr).relu()\n",
    "        h = self.lin1(h).relu()\n",
    "        #print(h)\n",
    "        h = F.dropout(h, p=0.1, training=self.training)\n",
    "        out = self.lin2(h)[:,0]\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleGAT_1(\n",
       "  (conv1): GATv2Conv(165, 16, heads=4)\n",
       "  (conv2): GATv2Conv(64, 16, heads=4)\n",
       "  (lin1): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (lin2): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load('../new_SREBP2_2.pt')\n",
    "model_path = '../SimpleGAT_1_model_lr5e-05_dp_0.0SREBP2.pth'\n",
    "model = SimpleGAT_1(data,dim = 16)\n",
    "model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'S',\n",
       " '1': 'ES',\n",
       " '2': 'TS',\n",
       " '3': 'DS',\n",
       " '4': 'EES',\n",
       " '5': 'ETS',\n",
       " '6': 'EDS',\n",
       " '7': 'TES',\n",
       " '8': 'TTS',\n",
       " '9': 'TDS',\n",
       " '10': 'DES',\n",
       " '11': 'DTS',\n",
       " '12': 'DDS',\n",
       " '13': 'EEES',\n",
       " '14': 'EETS',\n",
       " '15': 'EEDS',\n",
       " '16': 'ETES',\n",
       " '17': 'ETTS',\n",
       " '18': 'ETDS',\n",
       " '19': 'EDES',\n",
       " '20': 'EDTS',\n",
       " '21': 'EDDS',\n",
       " '22': 'TEES',\n",
       " '23': 'TETS',\n",
       " '24': 'TEDS',\n",
       " '25': 'TTES',\n",
       " '26': 'TTTS',\n",
       " '27': 'TTDS',\n",
       " '28': 'TDES',\n",
       " '29': 'TDTS',\n",
       " '30': 'TDDS',\n",
       " '31': 'DEES',\n",
       " '32': 'DETS',\n",
       " '33': 'DEDS',\n",
       " '34': 'DTES',\n",
       " '35': 'DTTS',\n",
       " '36': 'DTDS',\n",
       " '37': 'DDES',\n",
       " '38': 'DDTS',\n",
       " '39': 'DDDS',\n",
       " '40': 'has_path',\n",
       " '41': 'num_paths',\n",
       " '42': 'max_path_score',\n",
       " '43': 'max_degree_score',\n",
       " '44': 'thermo0',\n",
       " '45': 'thermo1',\n",
       " '46': 'thermo2',\n",
       " '47': 'thermo3',\n",
       " '48': 'thermo4',\n",
       " '49': 'thermo5',\n",
       " '50': 'thermo6',\n",
       " '51': 'RNA line ab',\n",
       " '52': 'binary_RNA line ab',\n",
       " '53': 'endosomes',\n",
       " '54': 'secretory',\n",
       " '55': 'vesicles',\n",
       " '56': 'cytoplasmic bodies',\n",
       " '57': 'mitochondria',\n",
       " '58': 'aggresome',\n",
       " '59': 'focal adhesion sites',\n",
       " '60': 'cytoplasm',\n",
       " '61': 'nucleoli',\n",
       " '62': 'cell junctions',\n",
       " '63': 'secreted proteins',\n",
       " '64': 'endoplasmic reticulum',\n",
       " '65': 'centrosome',\n",
       " '66': 'mitotic chromosome',\n",
       " '67': 'rods & rings',\n",
       " '68': 'actin filaments',\n",
       " '69': 'centriolar satellite',\n",
       " '70': 'cleavage furrow',\n",
       " '71': 'plasma membrane',\n",
       " '72': 'endomembrane system',\n",
       " '73': 'nucleoli fibrillar center',\n",
       " '74': 'cytokinetic bridge',\n",
       " '75': 'lysosomes',\n",
       " '76': 'midbody ring',\n",
       " '77': 'cytosol',\n",
       " '78': 'mitotic spindle',\n",
       " '79': 'lipid droplets',\n",
       " '80': 'nuclear bodies',\n",
       " '81': 'nucleoli rim',\n",
       " '82': 'nucleoplasm',\n",
       " '83': 'intermediate filaments',\n",
       " '84': 'golgi apparatus',\n",
       " '85': 'microtubule ends',\n",
       " '86': 'nucleus',\n",
       " '87': 'midbody',\n",
       " '88': 'microtubules',\n",
       " '89': 'kinetochore',\n",
       " '90': 'nuclear membrane',\n",
       " '91': 'peroxisomes',\n",
       " '92': 'nuclear speckles',\n",
       " '93': 'miss_subcell',\n",
       " '94': 'go_feature_0',\n",
       " '95': 'go_feature_1',\n",
       " '96': 'go_feature_2',\n",
       " '97': 'go_feature_3',\n",
       " '98': 'go_feature_4',\n",
       " '99': 'go_feature_5',\n",
       " '100': 'go_feature_6',\n",
       " '101': 'go_feature_7',\n",
       " '102': 'go_feature_8',\n",
       " '103': 'go_feature_9',\n",
       " '104': 'go_feature_10',\n",
       " '105': 'go_feature_11',\n",
       " '106': 'go_feature_12',\n",
       " '107': 'go_feature_13',\n",
       " '108': 'go_feature_14',\n",
       " '109': 'go_feature_15',\n",
       " '110': 'go_feature_16',\n",
       " '111': 'go_feature_17',\n",
       " '112': 'go_feature_18',\n",
       " '113': 'go_feature_19',\n",
       " '114': 'go_feature_20',\n",
       " '115': 'go_feature_21',\n",
       " '116': 'go_feature_22',\n",
       " '117': 'go_feature_23',\n",
       " '118': 'go_feature_24',\n",
       " '119': 'go_feature_25',\n",
       " '120': 'go_feature_26',\n",
       " '121': 'go_feature_27',\n",
       " '122': 'go_feature_28',\n",
       " '123': 'go_feature_29',\n",
       " '124': 'go_feature_30',\n",
       " '125': 'go_feature_31',\n",
       " '126': 'go_feature_32',\n",
       " '127': 'go_feature_33',\n",
       " '128': 'go_feature_34',\n",
       " '129': 'go_feature_35',\n",
       " '130': 'go_feature_36',\n",
       " '131': 'go_feature_37',\n",
       " '132': 'go_feature_38',\n",
       " '133': 'go_feature_39',\n",
       " '134': 'go_feature_40',\n",
       " '135': 'go_feature_41',\n",
       " '136': 'go_feature_42',\n",
       " '137': 'go_feature_43',\n",
       " '138': 'go_feature_44',\n",
       " '139': 'go_feature_45',\n",
       " '140': 'go_feature_46',\n",
       " '141': 'go_feature_47',\n",
       " '142': 'go_feature_48',\n",
       " '143': 'go_feature_49',\n",
       " '144': 'go_feature_50',\n",
       " '145': 'go_feature_51',\n",
       " '146': 'go_feature_52',\n",
       " '147': 'go_feature_53',\n",
       " '148': 'go_feature_54',\n",
       " '149': 'go_feature_55',\n",
       " '150': 'go_feature_56',\n",
       " '151': 'go_feature_57',\n",
       " '152': 'go_feature_58',\n",
       " '153': 'go_feature_59',\n",
       " '154': 'go_feature_60',\n",
       " '155': 'go_feature_61',\n",
       " '156': 'go_feature_62',\n",
       " '157': 'go_feature_63',\n",
       " '158': 'Has_Missing',\n",
       " '159': 'RWR_target_0.2',\n",
       " '160': 'RWR_target_0.4',\n",
       " '161': 'RWR_target_0.6',\n",
       " '162': 'diffusion_score_fold2_RWR_0.2',\n",
       " '163': 'diffusion_score_fold2_RWR_0.4',\n",
       " '164': 'diffusion_score_fold2_RWR_0.6'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../feature_index.json') as json_file:\n",
    "    feat_labels = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract node labels and testing nodes from node order \n",
    "\n",
    "\"\"\" \n",
    "# 9606.ENSP00000289989 lowest False Negative / predicted value: 0.0281679704785347 / node index: 17397\n",
    "# 9606.ENSP00000358777 highest True Positive / predicted value: 0.9995648264884949 / node index: 9005\n",
    "# 9606.ENSP00000216099 lowest True Negative / predicted value: 7.5380116e-30 / node index: 8665\n",
    "# 9606.ENSP00000357637 highest False Positive / predicted value: 0.9998927 / node index: 12633\n",
    "# 9606.ENSP00000357226 furthest to target with label 0 / predicted value: 1.4533093e-07 / node index: 18233\n",
    "# 9606.ENSP00000344741 closest to target with label 1 / predicted value: 0.8364509 / node index: 12257\n",
    "# 9606.ENSP00000470087 closest to target with label 0 / predicted value: 0.3407591 / node index: 1674\n",
    "# 9606.ENSP00000289989 furthest to target with label 1 / predicted value: 0.02816797 / node index: 17397\n",
    "# 9606.ENSP00000348069: SREBF1  / predicted value: 0.55870503 / node index: 6334\n",
    "# 9606.ENSP00000370695: EXCO1 / predicted value: 0.50875914/ node index: 1883\n",
    "\"\"\"\n",
    "\n",
    "with open('../node_order.pickle', 'rb') as f:\n",
    "    node_order = pickle.load(f)\n",
    "\n",
    "node_id_labels = list(node_order.keys())\n",
    "\n",
    "test_nodes = [node_order['9606.ENSP00000289989'], # lowest False Negative / predicted value: 0.0281679704785347 / node index: 17397\n",
    "                node_order['9606.ENSP00000358777'], # highest True Positive / predicted value: 0.9995648264884949 / node index: 9005\n",
    "                node_order['9606.ENSP00000216099'], # lowest True Negative / predicted value: 7.5380116e-30 / node index: 8665\n",
    "                node_order['9606.ENSP00000357637'],  # highest False Positive / predicted value: 0.9998927 / node index: 12633\n",
    "                node_order['9606.ENSP00000357226'], # furthest to target with label 0 / predicted value: 1.4533093e-07 / node index: 18233\n",
    "                node_order['9606.ENSP00000344741'], # closest to target with label 1 / predicted value: 0.8364509 / node index: 12257\n",
    "                node_order['9606.ENSP00000470087'], # closest to target with label 0 / predicted value: 0.3407591 / node index: 1674\n",
    "                node_order['9606.ENSP00000289989'], # furthest to target with label 1 / predicted value: 0.02816797 / node index: 17397\n",
    "                node_order['9606.ENSP00000348069'], # SREBF1  / predicted value: 0.55870503 / node index: 6334\n",
    "                node_order['9606.ENSP00000370695']] # : EXCO1 / predicted value: 0.50875914/ node index: 1883 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stringdb_alias'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get node labels for gene ids\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstringdb_alias\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HGNCMapper\n\u001b[1;32m      5\u001b[0m mapper \u001b[38;5;241m=\u001b[39m HGNCMapper(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../9606.protein.info.v11.5.txt.gz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../9606.protein.aliases.v11.5.txt.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m node_series \u001b[38;5;241m=\u001b[39m mapper\u001b[38;5;241m.\u001b[39mget_hgnc_ids(node_id_labels)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stringdb_alias'"
     ]
    }
   ],
   "source": [
    "# get node labels for gene ids\n",
    "\n",
    "from stringdb_alias import HGNCMapper\n",
    "\n",
    "mapper = HGNCMapper('../9606.protein.info.v11.5.txt.gz', '../9606.protein.aliases.v11.5.txt.gz')\n",
    "\n",
    "node_series = mapper.get_hgnc_ids(node_id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            C8orf58\n",
       "1            ATP6AP1\n",
       "2           APOBEC3D\n",
       "3               EBF3\n",
       "4            C1orf61\n",
       "5             INSIG1\n",
       "6    ENSG00000268643\n",
       "7            C8orf58\n",
       "8             SREBF1\n",
       "9              EXOC1\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper.get_hgnc_ids(['9606.ENSP00000289989', # lowest False Negative / predicted value: 0.0281679704785347 / node index: 17397\n",
    "                '9606.ENSP00000358777', # highest True Positive / predicted value: 0.9995648264884949 / node index: 9005\n",
    "                '9606.ENSP00000216099', # lowest True Negative / predicted value: 7.5380116e-30 / node index: 8665\n",
    "                '9606.ENSP00000357637',  # highest False Positive / predicted value: 0.9998927 / node index: 12633\n",
    "                '9606.ENSP00000357226', # furthest to target with label 0 / predicted value: 1.4533093e-07 / node index: 18233\n",
    "                '9606.ENSP00000344741', # closest to target with label 1 / predicted value: 0.8364509 / node index: 12257\n",
    "                '9606.ENSP00000470087', # closest to target with label 0 / predicted value: 0.3407591 / node index: 1674\n",
    "                '9606.ENSP00000289989', # furthest to target with label 1 / predicted value: 0.02816797 / node index: 17397\n",
    "                '9606.ENSP00000348069', # SREBF1  / predicted value: 0.55870503 / node index: 6334\n",
    "                '9606.ENSP00000370695'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals = [10, 20, 40, 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_fidelity_score(fids):\n",
    "    \"\"\"\n",
    "    Takes in list of fidelity scores across multiple instances, and returns overall fidelity score at the model level\n",
    "    \"\"\"\n",
    "    return 1 - sum(fids)/len(fids)\n",
    "\n",
    "def neg_fidelity_score(fids):\n",
    "    return sum(fids) / len(fids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of Node Features\n",
    "\n",
    "In this experiment, the goal is to assess the importance of node features alone by setting the edge mask to None. We will then measure fidelity across different values of k.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GNN_attr_feature_experiment(k_vals, test_nodes):\n",
    "    # measure fidelity across k without edge mask\n",
    "    wall_times = []\n",
    "    process_times = []\n",
    "    explanations = {k:[] for k in k_vals}\n",
    "    fid_pos_overall = []\n",
    "    fid_neg_overall = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=GNNExplainer(epochs=200),\n",
    "            explanation_type='model',\n",
    "            node_mask_type='attributes',\n",
    "            edge_mask_type=None,\n",
    "            threshold_config=dict(\n",
    "                threshold_type=\"topk\",\n",
    "                value=k\n",
    "            ),\n",
    "            model_config=dict(\n",
    "                mode='binary_classification',\n",
    "                task_level='node',\n",
    "                return_type='probs',\n",
    "            ),\n",
    "        )\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        for node in test_nodes:\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            explanation = explainer(data.x, data.edge_index, index = node, edge_attr=data.edge_attr)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations[k].append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        fid_pos_overall.append(pos_fidelity_score(fid_pos))\n",
    "        fid_neg_overall.append(neg_fidelity_score(fid_neg))\n",
    "        \n",
    "\n",
    "    return {'positive_fid' : fid_pos_overall, 'negative_fid': fid_neg_overall, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_attr_node_importance = GNN_attr_feature_experiment(k_vals, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_attr_node_importance['positive_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Positive Fidelity')\n",
    "plt.title('Positive Fidelity of GNN Explainer with Attributes with Edge Mask=None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_attr_node_importance['negative_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Negative Fidelity')\n",
    "plt.title('Negative Fidelity of GNN Explainer with Attributes with Edge Mask=None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GNN_comm_feature_experiment(k_vals, test_nodes):\n",
    "    # measure fidelity across k without edge mask\n",
    "    wall_times = []\n",
    "    process_times = []\n",
    "    explanations = {k:[] for k in k_vals}\n",
    "    fid_pos_overall = []\n",
    "    fid_neg_overall = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=GNNExplainer(epochs=200),\n",
    "            explanation_type='model',\n",
    "            node_mask_type='common_attributes',\n",
    "            edge_mask_type=None,\n",
    "            threshold_config=dict(\n",
    "                threshold_type=\"topk\",\n",
    "                value=k\n",
    "            ),\n",
    "            model_config=dict(\n",
    "                mode='binary_classification',\n",
    "                task_level='node',\n",
    "                return_type='probs',\n",
    "            ),\n",
    "        )\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        for node in test_nodes:\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            explanation = explainer(data.x, data.edge_index, index = node)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations[k].append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        fid_pos_overall.append(pos_fidelity_score(fid_pos))\n",
    "        fid_neg_overall.append(neg_fidelity_score(fid_neg))\n",
    "        \n",
    "\n",
    "    return {'positive_fid' : fid_pos_overall, 'negative_fid': fid_neg_overall, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_comm_node_importance = GNN_comm_feature_experiment(k_vals, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_comm_node_importance['positive_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Positive Fidelity')\n",
    "plt.title('Positive Fidelity of GNN Explainer with Common Attributes with Edge Mask=None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_comm_node_importance['negative_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Negative Fidelity')\n",
    "plt.title('Negative Fidelity of GNN Explainer with Common Attributes with Edge Mask=None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GM_attr_feature_experiment(k_vals, test_nodes):\n",
    "    # measure fidelity across k without edge mask\n",
    "    wall_times = []\n",
    "    process_times = []\n",
    "    explanations = {k:[] for k in k_vals}\n",
    "    fid_pos_overall = []\n",
    "    fid_neg_overall = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=GraphMaskExplainer(2, epochs=5),\n",
    "            explanation_type='model',\n",
    "            node_mask_type='attributes',\n",
    "            edge_mask_type=None,\n",
    "            threshold_config=dict(\n",
    "                threshold_type=\"topk\",\n",
    "                value=k\n",
    "            ),\n",
    "            model_config=dict(\n",
    "                mode='binary_classification',\n",
    "                task_level='node',\n",
    "                return_type='probs',\n",
    "            ),\n",
    "        )\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        for node in test_nodes:\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            explanation = explainer(data.x, data.edge_index, index = node)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations[k].append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        fid_pos_overall.append(pos_fidelity_score(fid_pos))\n",
    "        fid_neg_overall.append(neg_fidelity_score(fid_neg))\n",
    "        \n",
    "\n",
    "    return {'positive_fid' : fid_pos_overall, 'negative_fid': fid_neg_overall, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_attr_node_importance = GM_attr_feature_experiment(k_vals, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_comm_node_importance['positive_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Positive Fidelity')\n",
    "plt.title('Positive Fidelity of GraphMask with Attributes with Edge Mask=None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_comm_node_importance['negative_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Negative Fidelity')\n",
    "plt.title('Negative Fidelity of GraphMask with Attributes with Edge Mask=None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GM_comm_feature_experiment(k_vals, test_nodes):\n",
    "    # measure fidelity across k without edge mask\n",
    "    wall_times = []\n",
    "    process_times = []\n",
    "    explanations = {k:[] for k in k_vals}\n",
    "    fid_pos_overall = []\n",
    "    fid_neg_overall = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=GraphMaskExplainer(2, epochs=5),\n",
    "            explanation_type='model',\n",
    "            node_mask_type='common_attributes',\n",
    "            edge_mask_type=None,\n",
    "            threshold_config=dict(\n",
    "                threshold_type=\"topk\",\n",
    "                value=k\n",
    "            ),\n",
    "            model_config=dict(\n",
    "                mode='binary_classification',\n",
    "                task_level='node',\n",
    "                return_type='probs',\n",
    "            ),\n",
    "        )\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        for node in test_nodes:\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            explanation = explainer(data.x, data.edge_index, index = node)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations[k].append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        fid_pos_overall.append(pos_fidelity_score(fid_pos))\n",
    "        fid_neg_overall.append(neg_fidelity_score(fid_neg))\n",
    "        \n",
    "\n",
    "    return {'positive_fid' : fid_pos_overall, 'negative_fid': fid_neg_overall, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_attr_node_importance = GM_attr_feature_experiment(k_vals, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_comm_node_importance['positive_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Positive Fidelity')\n",
    "plt.title('Positive Fidelity of GraphMask with Common Attributes with Edge Mask=None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_comm_node_importance['negative_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Negative Fidelity')\n",
    "plt.title('Negative Fidelity of GraphMask with Common Attributes with Edge Mask=None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot fidelity curves for subgraphs with various values of k (10, 20, 40, 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_attr_acrossk(k_vals, test_nodes):\n",
    "    wall_times = []\n",
    "    process_times = []\n",
    "    explanations = {k:[] for k in k_vals}\n",
    "    fid_pos_overall = []\n",
    "    fid_neg_overall = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=GNNExplainer(epochs=200),\n",
    "            explanation_type='model',\n",
    "            node_mask_type='attributes',\n",
    "            edge_mask_type='object',\n",
    "            threshold_config=dict(\n",
    "                threshold_type=\"topk\",\n",
    "                value=k\n",
    "            ),\n",
    "            model_config=dict(\n",
    "                mode='binary_classification',\n",
    "                task_level='node',\n",
    "                return_type='probs',\n",
    "            ),\n",
    "        )\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        for node in test_nodes:\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            explanation = explainer(data.x, data.edge_index, index = node)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations[k].append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        fid_pos_overall.append(pos_fidelity_score(fid_pos))\n",
    "        fid_neg_overall.append(neg_fidelity_score(fid_neg))\n",
    "        \n",
    "\n",
    "    return {'positive_fid' : fid_pos_overall, 'negative_fid': fid_neg_overall, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_attr_k_importance = gnn_attr_acrossk(k_vals, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_attr_k_importance['positive_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Positive Fidelity')\n",
    "plt.title('Positive Fidelity of GNNExplainer with Attributes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_attr_k_importance['negative_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Negative Fidelity')\n",
    "plt.title('Negative Fidelity of GNNExplainer with Attributes ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_comm_acrossk(k_vals, test_nodes):\n",
    "    wall_times = []\n",
    "    process_times = []\n",
    "    explanations = {k:[] for k in k_vals}\n",
    "    fid_pos_overall = []\n",
    "    fid_neg_overall = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=GNNExplainer(epochs=200),\n",
    "            explanation_type='model',\n",
    "            node_mask_type='common_attributes',\n",
    "            edge_mask_type='object',\n",
    "            threshold_config=dict(\n",
    "                threshold_type=\"topk\",\n",
    "                value=k\n",
    "            ),\n",
    "            model_config=dict(\n",
    "                mode='binary_classification',\n",
    "                task_level='node',\n",
    "                return_type='probs',\n",
    "            ),\n",
    "        )\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        for node in test_nodes:\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            explanation = explainer(data.x, data.edge_index, index = node)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations[k].append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        fid_pos_overall.append(pos_fidelity_score(fid_pos))\n",
    "        fid_neg_overall.append(neg_fidelity_score(fid_neg))\n",
    "        \n",
    "\n",
    "    return {'positive_fid' : fid_pos_overall, 'negative_fid': fid_neg_overall, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_comm_k_importance = gnn_comm_acrossk(k_vals, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_comm_k_importance['positive_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Positive Fidelity')\n",
    "plt.title('Positive Fidelity of GNNExplainer with Common Attributes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_comm_k_importance['negative_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Negative Fidelity')\n",
    "plt.title('Negative Fidelity of GNNExplainer with Common Attributes ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg_acrossk(k_vals, test_nodes):\n",
    "    wall_times = []\n",
    "    process_times = []\n",
    "    explanations = {k:[] for k in k_vals}\n",
    "    fid_pos_overall = []\n",
    "    fid_neg_overall = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=PGExplainer(epochs=30, lr=0.003),\n",
    "            explanation_type='phenomenon',\n",
    "            edge_mask_type='object',\n",
    "            threshold_config=dict(\n",
    "                threshold_type=\"topk\",\n",
    "                value=k \n",
    "            ),\n",
    "            model_config=dict(\n",
    "                mode='binary_classification',\n",
    "                task_level='node',\n",
    "                return_type='probs',\n",
    "            ),\n",
    "        )\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        for node in test_nodes:\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            explanation = explainer(data.x, data.edge_index, index = node)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations[k].append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        fid_pos_overall.append(pos_fidelity_score(fid_pos))\n",
    "        fid_neg_overall.append(neg_fidelity_score(fid_neg))\n",
    "        \n",
    "\n",
    "    return {'positive_fid' : fid_pos_overall, 'negative_fid': fid_neg_overall, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_k_importance = pg_acrossk(k_vals, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_comm_k_importance['positive_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Positive Fidelity')\n",
    "plt.title('Positive Fidelity of PGExplainer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gnn_comm_k_importance['negative_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Negative Fidelity')\n",
    "plt.title('Negative Fidelity of PGExplainer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GM_attr_acrossk(k_vals, test_nodes):\n",
    "    # measure fidelity across k without edge mask\n",
    "    wall_times = []\n",
    "    process_times = []\n",
    "    explanations = {k:[] for k in k_vals}\n",
    "    fid_pos_overall = []\n",
    "    fid_neg_overall = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=GraphMaskExplainer(2, epochs=5),\n",
    "            explanation_type='model',\n",
    "            node_mask_type='attributes',\n",
    "            edge_mask_type='object',\n",
    "            threshold_config=dict(\n",
    "                threshold_type=\"topk\",\n",
    "                value=k\n",
    "            ),\n",
    "            model_config=dict(\n",
    "                mode='binary_classification',\n",
    "                task_level='node',\n",
    "                return_type='probs',\n",
    "            ),\n",
    "        )\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        for node in test_nodes:\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            explanation = explainer(data.x, data.edge_index, index = node)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations[k].append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        fid_pos_overall.append(pos_fidelity_score(fid_pos))\n",
    "        fid_neg_overall.append(neg_fidelity_score(fid_neg))\n",
    "        \n",
    "\n",
    "    return {'positive_fid' : fid_pos_overall, 'negative_fid': fid_neg_overall, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_attr_k_importance = GM_attr_acrossk(k_vals, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gm_attr_k_importance['positive_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Positive Fidelity')\n",
    "plt.title('Positive Fidelity of GraphMask with Attributes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gm_attr_k_importance['negative'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Negative Fidelity')\n",
    "plt.title('Negative Fidelity of GraphMask with Attributes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GM_comm_acrossk(k_vals, test_nodes):\n",
    "    # measure fidelity across k without edge mask\n",
    "    wall_times = []\n",
    "    process_times = []\n",
    "    explanations = {k:[] for k in k_vals}\n",
    "    fid_pos_overall = []\n",
    "    fid_neg_overall = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=GraphMaskExplainer(2, epochs=5),\n",
    "            explanation_type='model',\n",
    "            node_mask_type='common_attributes',\n",
    "            edge_mask_type='object',\n",
    "            threshold_config=dict(\n",
    "                threshold_type=\"topk\",\n",
    "                value=k\n",
    "            ),\n",
    "            model_config=dict(\n",
    "                mode='binary_classification',\n",
    "                task_level='node',\n",
    "                return_type='probs',\n",
    "            ),\n",
    "        )\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        for node in test_nodes:\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            explanation = explainer(data.x, data.edge_index, index = node)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations[k].append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        fid_pos_overall.append(pos_fidelity_score(fid_pos))\n",
    "        fid_neg_overall.append(neg_fidelity_score(fid_neg))\n",
    "        \n",
    "\n",
    "    return {'positive_fid' : fid_pos_overall, 'negative_fid': fid_neg_overall, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_comm_k_importance = GM_comm_acrossk(k_vals, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gm_comm_k_importance['positive_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Positive Fidelity')\n",
    "plt.title('Positive Fidelity of GraphMask with Common Attributes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, gm_comm_k_importance['negative_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Negative Fidelity')\n",
    "plt.title('Negative Fidelity of GraphMask with Common Attributes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revised stability calculations\n",
    "- Can we do 5  runs for each of 10  instances?\n",
    "    - Calculate average Jaccard similarity for each instance\n",
    "    - Make a box plot or something similar to show distribution of similarity measures across instances\n",
    "    - Per Yuriy’s suggestion, we could also calculate Ruzicka similarity (https://en.wikipedia.org/wiki/Jaccard_index) on soft masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define explainers\n",
    "gnn_attr = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type=\"topk\",\n",
    "        value=10 \n",
    "    ),\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "gnn_common = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='common_attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type=\"topk\",\n",
    "        value=10 \n",
    "    ),\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "pg = Explainer(\n",
    "    model=model,\n",
    "    algorithm=PGExplainer(epochs=30, lr=0.003),\n",
    "    explanation_type='phenomenon',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type=\"topk\",\n",
    "        value=10 \n",
    "    ),\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "gm_attr = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GraphMaskExplainer(2, epochs=5),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type=\"topk\",\n",
    "        value=10 \n",
    "    ),\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ), \n",
    ")\n",
    "\n",
    "gm_comm = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GraphMaskExplainer(2, epochs=5),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='common_attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type=\"topk\",\n",
    "        value=10 \n",
    "    ),\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "explainers = [gnn_attr, gnn_common, pg, gm_attr, gm_comm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stability_trial(explainer, test_nodes):\n",
    "    \"\"\"\n",
    "    One trial of a stability experiment - Using one explainer, finds an explanation on the input target node. \n",
    "    For each explanation, the positive fidelity score, negative fidelity score, wall runtime, process runtime, and explanation object are recorded.\n",
    "    Returns a dictionary with keys {'positive_fid', 'negative_fid',  'wall_times', 'process_times', 'explanations'}\n",
    "    This dict includes multiple explanations of the same explainer on the same node to explore stability \n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for node in test_nodes:\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        wall_times = []\n",
    "        process_times = []\n",
    "        explanations = []\n",
    "        for i in range(5):\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            explanation = explainer(data.x, data.edge_index, edge_attr=data.edge_attr, index = node)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations.append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        results[node] = {'positive_fid' : fid_pos, 'negative_fid': fid_neg, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg_stability_trial(explainer, test_nodes):\n",
    "    \"\"\"\n",
    "    One trial of a stability experiment - Using one explainer, finds an explanation on the input target node. \n",
    "    For each explanation, the positive fidelity score, negative fidelity score, wall runtime, process runtime, and explanation object are recorded.\n",
    "    Returns a dictionary with keys {'positive_fid', 'negative_fid',  'wall_times', 'process_times', 'explanations'}\n",
    "    This dict includes multiple explanations of the same explainer on the same node to explore stability \n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for node in test_nodes:\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        wall_times = []\n",
    "        process_times = []\n",
    "        explanations = []\n",
    "        for i in range(5):\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            for epoch in range(30):\n",
    "                loss = explainer.algorithm.train(epoch, model, data.x, data.edge_index,\n",
    "                                            target=data.y, index=node, edge_attr = data.edge_attr)\n",
    "\n",
    "            explanation = explainer(data.x, data.edge_index, target=data.y, index=node, edge_attr = data.edge_attr)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations.append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        results[node] = {'positive_fid' : fid_pos, 'negative_fid': fid_neg, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_jaccard(edge_mask1, edge_mask2):\n",
    "    edge_mask1 = np.array(edge_mask1)\n",
    "    edge_mask2 = np.array(edge_mask2)\n",
    "    edge_mask1[edge_mask1 > 0] = 1\n",
    "    edge_mask2[edge_mask2 > 0] = 1\n",
    "    intersection = np.sum(((edge_mask1 == edge_mask2) & (edge_mask1 == 1) & (edge_mask2 == 1)))\n",
    "    union = np.sum(edge_mask1 == 1) + np.sum((edge_mask2 == 1)) - intersection\n",
    "    return intersection / union\n",
    "\n",
    "def avg_edge_jaccard(explanations):\n",
    "    jaccards = []\n",
    "    for i in range(len(explanations)):\n",
    "        for j in range(i, len(explanations)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            exp1 = i\n",
    "            exp2 = j\n",
    "            edge_mask1 = explanations[i].edge_mask\n",
    "            edge_mask2 = explanations['explanations'][j].edge_mask\n",
    "            edge_sim = edge_jaccard(edge_mask1, edge_mask2)\n",
    "            jaccards.append(edge_sim)\n",
    "    return np.mean(jaccards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stability trial\n",
    "\n",
    "stability_results = []\n",
    "for explainer in explainers:\n",
    "    if explainer == pg:\n",
    "        result = pg_stability_trial(explainer, test_nodes)\n",
    "    else:\n",
    "        result = stability_trial(explainer, test_nodes)\n",
    "    stability_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make box plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = Explainer(\n",
    "    model=model,\n",
    "    algorithm=DummyExplainer(),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type=\"topk\",\n",
    "        value=10 \n",
    "    ),\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_acrossk(k_vals, test_nodes):\n",
    "    wall_times = []\n",
    "    process_times = []\n",
    "    explanations = {k:[] for k in k_vals}\n",
    "    fid_pos_overall = []\n",
    "    fid_neg_overall = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        explainer = Explainer(\n",
    "            model=model,\n",
    "            algorithm=DummyExplainer(),\n",
    "            explanation_type='model',\n",
    "            node_mask_type='attributes',\n",
    "            edge_mask_type='object',\n",
    "            threshold_config=dict(\n",
    "                threshold_type=\"topk\",\n",
    "                value=k \n",
    "            ),\n",
    "            model_config=dict(\n",
    "                mode='binary_classification',\n",
    "                task_level='node',\n",
    "                return_type='probs',\n",
    "            ),\n",
    "        )\n",
    "        fid_pos = []\n",
    "        fid_neg = []\n",
    "        for node in test_nodes:\n",
    "            start = time.time()\n",
    "            process_start = time.process_time()\n",
    "            explanation = explainer(data.x, data.edge_index, index = node)\n",
    "            process_end = time.process_time()\n",
    "            end = time.time()\n",
    "            fid = fidelity(explainer, explanation)\n",
    "            fid_pos.append(fid[0])\n",
    "            fid_neg.append(fid[1])\n",
    "            wall_times.append(end - start)\n",
    "            process_times.append(process_end - process_start)\n",
    "            explanations[k].append(explanation)\n",
    "            # explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "        fid_pos_overall.append(pos_fidelity_score(fid_pos))\n",
    "        fid_neg_overall.append(neg_fidelity_score(fid_neg))\n",
    "        \n",
    "\n",
    "    return {'positive_fid' : fid_pos_overall, 'negative_fid': fid_neg_overall, 'wall_times': wall_times, 'process_times': process_times, 'explanations': explanations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_k_importance = dummy_acrossk(k_vals, test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, dummy_k_importance['positive_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Positive Fidelity')\n",
    "plt.title('Positive Fidelity of DummyExplainer (Baseline)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_vals, dummy_k_importance['negative_fid'])\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Negative Fidelity')\n",
    "plt.title('Negative Fidelity of DummyExplainer (Baseline)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
