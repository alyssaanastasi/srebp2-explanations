{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Experiment\n",
    "\n",
    "In this experiment, I am running all three explanation methods over a set of 10 instances which include:\n",
    "\n",
    "- '9606.ENSP00000269228' # NPC1 which is known to have involvement in the cholesterol homeostasis process\n",
    "- '9606.ENSP00000289989' # Closest to SREBP2 and has label 1 (expected)\n",
    "- '9606.ENSP00000415836' # Far from SREBP2 and has label 0 (expected)\n",
    "- '9606.ENSP00000216180' # Closest to SREBP2 but has label 0 (unexpected)\n",
    "- '9606.ENSP00000359398' # Far from SREBP2 but has label 1 (Unexpected)\n",
    "- '9606.ENSP00000346046' # False Negative (lowest confidence)\n",
    "- '9606.ENSP00000473036' # True Negative (lowest confidence)\n",
    "- '9606.ENSP00000449270' # False Positive (highest confidence)\n",
    "- '9606.ENSP00000270176' # True Positive (highest confidence)\n",
    "\n",
    "From each method, I will measuring the metrics:\n",
    " \n",
    "- Runtime\n",
    "- Fidelity \n",
    "- Stability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in /opt/homebrew/lib/python3.11/site-packages (2.5.3)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from torch_geometric) (4.66.4)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from torch_geometric) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from torch_geometric) (1.13.1)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from torch_geometric) (2024.6.0)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.11/site-packages (from torch_geometric) (3.9.5)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: pyparsing in /opt/homebrew/lib/python3.11/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (from torch_geometric) (1.5.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/Owner/Library/Python/3.11/lib/python/site-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->torch_geometric) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->torch_geometric) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->torch_geometric) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->torch_geometric) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->torch_geometric) (2024.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/lib/python3.11/site-packages (0.18.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: torch==2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/lib/python3.11/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.15.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from torch==2.3.1->torchvision) (2024.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/Owner/Library/Python/3.11/lib/python/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/Owner/Library/Python/3.11/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Owner/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: graphviz in /opt/homebrew/lib/python3.11/site-packages (0.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install necessary packages\n",
    "\n",
    "%pip install torch_geometric # install pytorch geometric\n",
    "%pip install torchvision #install torchvision\n",
    "%pip install matplotlib #install matplotlib\n",
    "%pip install graphviz # install graphviz\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.explain import GNNExplainer,Explainer,GraphMaskExplainer,PGExplainer\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv\n",
    "from torch.nn import Linear,Softmax\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import pickle\n",
    "from torch_geometric.explain.metric import fidelity, characterization_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define GNN \n",
    "\n",
    "class SimpleGAT_1(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A graph attention network with 4 graph layers and 2 linear layers.\n",
    "    Uses v2 of graph attention that provides dynamic instead of static attention.\n",
    "    The graph layer dimension and number of attention heads can be specified.\n",
    "    \"\"\"\n",
    "    #torch.device('mps')\n",
    "    def __init__(self, dataset, dim=8, num_heads=4):\n",
    "        super(SimpleGAT_1, self).__init__()\n",
    "        torch.manual_seed(seed=123)\n",
    "        self.conv1 = GATv2Conv(in_channels=dataset.num_features, out_channels=dim, heads=num_heads,edge_dim=dataset.edge_attr.shape[1])\n",
    "        self.conv2 = GATv2Conv(in_channels=dim * num_heads, out_channels=dim, heads=num_heads,edge_dim=dataset.edge_attr.shape[1])\n",
    "        self.lin1 = Linear(dim * num_heads,dim)\n",
    "        self.lin2 = Linear(dim,1)\n",
    "\n",
    "    def forward(self, x, edge_index,edge_attr):\n",
    "        h = self.conv1(x, edge_index,edge_attr).relu()\n",
    "        h = self.conv2(h, edge_index,edge_attr).relu()\n",
    "        h = self.lin1(h).relu()\n",
    "        #print(h)\n",
    "        h = F.dropout(h, p=0.1, training=self.training)\n",
    "        out = self.lin2(h)[:,0]\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleGAT_1(\n",
       "  (conv1): GATv2Conv(165, 16, heads=4)\n",
       "  (conv2): GATv2Conv(64, 16, heads=4)\n",
       "  (lin1): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (lin2): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in data and fit GNN model \n",
    "\n",
    "data = torch.load('../SREBP2_0.pt')\n",
    "model_path = '../SimpleGAT_1_model_lr_0.0001_dp_0.7.pth'\n",
    "model = SimpleGAT_1(data,dim = 16)\n",
    "model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data to get feature labels and remove all elements of data that are not a feature label\n",
    "\n",
    "feat_labels = list(data.to_dict().keys())\n",
    "to_remove = ['edge_index', \n",
    " 'experimental',\n",
    " 'database',\n",
    " 'textmining',\n",
    " 'combined_score',\n",
    " 'binary_experimental',\n",
    " 'binary_database',\n",
    " 'binary_textmining',\n",
    " 'num_nodes',\n",
    " 'x',\n",
    " 'y',\n",
    " 'edge_attr',\n",
    " 'num_classes',\n",
    " 'label']\n",
    "\n",
    "for element in to_remove:\n",
    "    feat_labels.remove(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract node labels and testing nodes from node order \n",
    "\n",
    "\"\"\" \n",
    "- '9606.ENSP00000269228' # NPC1 which is known to have involvement in the cholesterol homeostasis process\n",
    "- '9606.ENSP00000289989' # Closest to SREBP2 and has label 1 (expected)\n",
    "- '9606.ENSP00000415836' # Far from SREBP2 and has label 0 (expected)\n",
    "- '9606.ENSP00000216180' # Closest to SREBP2 but has label 0 (unexpected)\n",
    "- '9606.ENSP00000359398' # Far from SREBP2 but has label 1 (Unexpected)\n",
    "- '9606.ENSP00000346046' # False Negative (lowest confidence)\n",
    "- '9606.ENSP00000473036' # True Negative (lowest confidence)\n",
    "- '9606.ENSP00000449270' # False Positive (highest confidence)\n",
    "- '9606.ENSP00000270176' # True Positive (highest confidence)\n",
    "\"\"\"\n",
    "\n",
    "with open('../node_order.pickle', 'rb') as f:\n",
    "    node_order = pickle.load(f)\n",
    "\n",
    "node_labels = list(node_order.keys())\n",
    "\n",
    "test_nodes = [node_order['9606.ENSP00000269228'], # NPC1 which is known to have involvement in the cholesterol homeostasis process\n",
    "                node_order['9606.ENSP00000289989'], # Closest to SREBP2 and has label 1 (expected)\n",
    "                node_order['9606.ENSP00000415836'], # Far from SREBP2 and has label 0 (expected)\n",
    "                node_order['9606.ENSP00000216180'], # Closest to SREBP2 but has label 0 (unexpected)\n",
    "                node_order['9606.ENSP00000359398'], # Far from SREBP2 but has label 1 (Unexpected)\n",
    "                node_order['9606.ENSP00000346046'], # False Negative (lowest confidence)\n",
    "                node_order['9606.ENSP00000473036'], # True Negative (lowest confidence)\n",
    "                node_order['9606.ENSP00000449270'], # False Positive (highest confidence)\n",
    "                node_order['9606.ENSP00000270176'] ]# True Positive (highest confidence) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define explainers\n",
    "gnn_attr = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type=\"topk\",\n",
    "        value=10 \n",
    "    ),\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "gnn_common = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='common_attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type=\"topk\",\n",
    "        value=10 \n",
    "    ),\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "pg = Explainer(\n",
    "    model=model,\n",
    "    algorithm=PGExplainer(epochs=30, lr=0.003),\n",
    "    explanation_type='phenomenon',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type=\"topk\",\n",
    "        value=10 \n",
    "    ),\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "gm_attr = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GraphMaskExplainer(2, epochs=5),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type=\"topk\",\n",
    "        value=10 \n",
    "    ),\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ), \n",
    ")\n",
    "\n",
    "gm_comm = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GraphMaskExplainer(2, epochs=5),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='common_attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type=\"topk\",\n",
    "        value=10 \n",
    "    ),\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_fidelity_score(fids):\n",
    "    return 1 - sum(fids)/len(fids)\n",
    "\n",
    "def neg_fidelity_score(fids):\n",
    "    return 1 - sum(fids)/len(fids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def trial(explainer):\n",
    "    fid_pos = []\n",
    "    fid_neg = []\n",
    "    times = []\n",
    "    explanations = []\n",
    "\n",
    "    for node in test_nodes:\n",
    "        start = time.time()\n",
    "        explanation = explainer(data.x, data.edge_index, edge_attr=data.edge_attr, index = node)\n",
    "        end = time.time()\n",
    "        fid = fidelity(explainer, explanation)\n",
    "        fid_pos.append(fid[0])\n",
    "        fid_neg.append(fid[1])\n",
    "        times.append(end - start)\n",
    "        explanations.append(explanation)\n",
    "        explanation.visualize_subgraph(path=f\"trial_figs/{explainer}_{node}.pdf\", backend='graphviz')\n",
    "\n",
    "    return {'positive_fid' : fid_pos, 'negative_fid': fid_neg, 'time': times, 'explanations': explanations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trial_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 2\u001b[0m trial_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgnn_attr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgnn_attr\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[71], line 10\u001b[0m, in \u001b[0;36mtrial\u001b[0;34m(explainer)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m test_nodes:\n\u001b[1;32m      9\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 10\u001b[0m     explanation \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m     fid \u001b[38;5;241m=\u001b[39m fidelity(explainer, explanation)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch_geometric/explain/explainer.py:205\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 205\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(training)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:87\u001b[0m, in \u001b[0;36mGNNExplainer.forward\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeterogeneous graphs not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m node_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_mask(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_mask,\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_node_mask,\n\u001b[1;32m     92\u001b[0m     apply_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m )\n\u001b[1;32m     94\u001b[0m edge_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_mask(\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_mask,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_edge_mask,\n\u001b[1;32m     97\u001b[0m     apply_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     98\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:139\u001b[0m, in \u001b[0;36mGNNExplainer._train\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     y_hat, y \u001b[38;5;241m=\u001b[39m y_hat[index], y[index]\n\u001b[1;32m    137\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(y_hat, y)\n\u001b[0;32m--> 139\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# In the first iteration, we collect the nodes and edges that are\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# involved into making the prediction. These are all the nodes and\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# edges with gradient != 0 (without regularization applied).\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trial_data = {}\n",
    "exps = [gnn_attr, gnn_common, pg, gm_attr, gm_comm]\n",
    "\n",
    "for exp in exps:\n",
    "    trial_data[exp] = trial(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
